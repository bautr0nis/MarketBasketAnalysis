{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-12T11:56:19.202685Z",
     "start_time": "2024-10-12T11:56:18.873102Z"
    }
   },
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T11:56:24.269682Z",
     "start_time": "2024-10-12T11:56:24.038337Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load Dataset\n",
    "data = pd.read_csv('../2 - Data/develop.csv')  # Update the path accordingly\n",
    "target = 'Ins'  # Define the target variable\n",
    "X = data.drop(columns=[target])\n",
    "y = data[target]\n",
    "\n",
    "# Encode categorical variables\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Apply SMOTE to handle class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ],
   "id": "8e6cd5baf4fb46a4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T12:01:50.332356Z",
     "start_time": "2024-10-12T11:56:25.664278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define parameter grid for Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Initialize Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform GridSearchCV for Random Forest\n",
    "rf_grid_search = GridSearchCV(estimator=rf, param_grid=rf_params, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "rf_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best parameters and model\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "print(f\"Best Random Forest Parameters: {rf_grid_search.best_params_}\")"
   ],
   "id": "f657f1f6ef1bf3d0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best Random Forest Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:30:06.614271Z",
     "start_time": "2024-09-21T18:29:29.673758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define parameter grid for XGBoost\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# Perform GridSearchCV for XGBoost\n",
    "xgb_grid_search = GridSearchCV(estimator=xgb, param_grid=xgb_params, cv=cv, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "xgb_grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Best parameters and model\n",
    "best_xgb = xgb_grid_search.best_estimator_\n",
    "print(f\"Best XGBoost Parameters: {xgb_grid_search.best_params_}\")"
   ],
   "id": "9ff7dfebc0490643",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best XGBoost Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 1, 'n_estimators': 300}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-21T18:30:11.579212Z",
     "start_time": "2024-09-21T18:30:11.561447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensemble Model (Simple Averaging)\n",
    "ensemble_pred = (rf_pred + xgb_pred) / 2\n",
    "ensemble_auc = roc_auc_score(y_test, ensemble_pred)\n",
    "ensemble_acc = accuracy_score(y_test, (ensemble_pred > 0.5).astype(int))\n",
    "\n",
    "# Print Results\n",
    "print(f\"Ensemble Model AUC: {ensemble_auc:.3f}\")\n",
    "print(f\"Ensemble Model Accuracy: {ensemble_acc:.3f}\")\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, (ensemble_pred > 0.5).astype(int)))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, (ensemble_pred > 0.5).astype(int))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ],
   "id": "60f35fe199be7623",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model AUC: 0.814\n",
      "Ensemble Model Accuracy: 0.757\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.85      0.82      4218\n",
      "           1       0.67      0.58      0.62      2235\n",
      "\n",
      "    accuracy                           0.76      6453\n",
      "   macro avg       0.73      0.71      0.72      6453\n",
      "weighted avg       0.75      0.76      0.75      6453\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3593  625]\n",
      " [ 943 1292]]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import shap\n",
    "\n",
    "# Initialize SHAP for each model\n",
    "rf_explainer = shap.TreeExplainer(rf_model)\n",
    "xgb_explainer = shap.Explainer(xgb_model)\n",
    "\n",
    "# Calculate SHAP values for each model\n",
    "rf_shap_values = rf_explainer.shap_values(X_test)\n",
    "xgb_shap_values = xgb_explainer.shap_values(X_test)\n",
    "\n",
    "# Average SHAP values for ensemble\n",
    "ensemble_shap_values = (rf_shap_values + xgb_shap_values) / 2\n",
    "\n",
    "# SHAP summary plot\n",
    "shap.summary_plot(ensemble_shap_values, X_test, plot_type=\"bar\")\n",
    "\n",
    "# SHAP dependence plot for a specific feature\n",
    "shap.dependence_plot(\"CD\", ensemble_shap_values, X_test)  # Replace \"Feature_Name\" with the feature you want to inspect"
   ],
   "id": "39dd966748502568",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "from alibi.explainers import AnchorTabular\n",
    "\n",
    "explainer = AnchorTabular(predict_fn=ensemble_model.predict, feature_names=X_train.columns.tolist())\n",
    "explainer.fit(X_train.values, disc_perc=(25, 50, 75))  # Discretize features\n",
    "explanation = explainer.explain(X_test.values[0])\n",
    "print(explanation)"
   ],
   "id": "18a44aee6aa7b4f5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from skater.core.explanations import Interpretation\n",
    "from skater.model import InMemoryModel\n",
    "\n",
    "interpreter = Interpretation(X_test, feature_names=X_test.columns)\n",
    "model = InMemoryModel(ensemble_model.predict_proba, examples=X_train)\n",
    "plots = interpreter.feature_importance.plot_feature_importance(model)"
   ],
   "id": "bd885cdf59e1e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from dice_ml import Dice\n",
    "from dice_ml.utils import helpers\n",
    "\n",
    "# Initialize DICE with the model and data\n",
    "dice_data = helpers.load_adult_income_dataset()\n",
    "d = Dice(dice_data, model=model, method=\"random\")\n",
    "explanation = d.generate_counterfactuals(X_test.iloc[0:1], total_CFs=5, desired_class=\"opposite\")\n",
    "explanation.visualize_as_dataframe()"
   ],
   "id": "8f5cf06293c66316"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4d8b410f0909b8bc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
